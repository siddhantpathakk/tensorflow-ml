<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Classification - Tensorflow ML</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../assets/_mkdocstrings.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Classification";
        var mkdocs_page_input_path = "class.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-ABC123"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', "G-ABC123");
      </script>
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> Tensorflow ML
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../status/">Support</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../reg/">Regression</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="./">Classification</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#classification.naive_bayes.gaussian">gaussian</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#classification.naive_bayes.bernoulli">bernoulli</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#classification.logistic_regression">logistic_regression</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#classification.decision_tree">decision_tree</a>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../tutorials/">Tutorials</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../about/">About the package</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../author/">About the author</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../next/">What's new</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">Tensorflow ML</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a> &raquo;</li>
      <li class="breadcrumb-item active">Classification</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/siddhantpathakk/tensorflow-ml/edit/master/docs/class.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="classification">Classification</h1>


<div class="doc doc-object doc-module">



<h2 id="classification.naive_bayes.gaussian" class="doc doc-heading">
            <code>classification.naive_bayes.gaussian</code>


</h2>

  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h3 id="classification.naive_bayes.gaussian.GaussianNaiveBayes" class="doc doc-heading">
          <code>GaussianNaiveBayes</code>


</h3>


  <div class="doc doc-contents ">

  
      <p>Defines a Gaussian Naive Bayes classifier in Python using
TensorFlow.</p>
<p>Gaussian Naive Bayes is a classification algorithm that assumes that the features follow a normal
distribution. It is a variant of the Naive Bayes algorithm that is used for classification tasks. It is
called "naive" because it assumes that the features are independent of each other. This assumption is
called "naive" because it is rarely true in real-world applications. However, despite this assumption,
Gaussian Naive Bayes performs surprisingly well in many cases.</p>


  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h4 id="classification.naive_bayes.gaussian.GaussianNaiveBayes.evaluate" class="doc doc-heading">
<code class="highlight language-python"><span class="n">evaluate</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The evaluate function calculates the accuracy of the predictions made by the model.</p>
<h6 id="classification.naive_bayes.gaussian.GaussianNaiveBayes.evaluate--parameters">Parameters</h6>
<pre><code>features : np.ndarray
    The `features` parameter is a np.ndarray that represents the input features for training the
    model. It has a shape of `(num_samples, num_features)`, where `num_samples` is the number of
    training samples and `num_features` is the number of features for each sample

labels : np.ndarray
    The "labels" parameter is a np.ndarray that contains the class labels for each data point in the
    "features" array. Each element in the "labels" array corresponds to the class label of the
    corresponding data point in the "features" array
</code></pre>
<h6 id="classification.naive_bayes.gaussian.GaussianNaiveBayes.evaluate--returns">Returns</h6>
<pre><code>accuracy : float
    The `accuracy` parameter is a float that represents the accuracy of the predictions made by the
    model.
</code></pre>

  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="classification.naive_bayes.gaussian.GaussianNaiveBayes.fit" class="doc doc-heading">
<code class="highlight language-python"><span class="n">fit</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The <code>fit</code> function trains a Gaussian Naive Bayes classifier using TensorFlow by calculating class
priors and feature parameters, and optimizing them using gradient descent.</p>
<h6 id="classification.naive_bayes.gaussian.GaussianNaiveBayes.fit--parameters">Parameters</h6>
<pre><code>features : np.ndarray
    The `features` parameter is a np.ndarray that represents the input features for training the
    model. It has a shape of `(num_samples, num_features)`, where `num_samples` is the number of
    training samples and `num_features` is the number of features for each sample

labels : np.ndarray
    The "labels" parameter is a np.ndarray that contains the class labels for each data point in the
    "features" array. Each element in the "labels" array corresponds to the class label of the
    corresponding data point in the "features" array

epochs : int
    The `epochs` parameter is an integer that represents the number of epochs to train the model for.
    An epoch is one iteration over the entire training dataset. For example, if the training dataset
    has 1000 samples and the batch size is 100, then it will take 10 iterations to complete 1 epoch.
    The default value is 10.
</code></pre>

  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="classification.naive_bayes.gaussian.GaussianNaiveBayes.predict" class="doc doc-heading">
<code class="highlight language-python"><span class="n">predict</span><span class="p">(</span><span class="n">features</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The <code>predict</code> function takes in a set of features and returns the predicted class labels using a
Gaussian Naive Bayes classifier.</p>
<h6 id="classification.naive_bayes.gaussian.GaussianNaiveBayes.predict--parameters">Parameters</h6>
<pre><code>features : np.ndarray
    The `features` parameter is a np.ndarray that represents the input features for training the
    model. It has a shape of `(num_samples, num_features)`, where `num_samples` is the number of
    training samples and `num_features` is the number of features for each sample
</code></pre>
<h6 id="classification.naive_bayes.gaussian.GaussianNaiveBayes.predict--returns">Returns</h6>
<pre><code>predictions : np.ndarray
    The `predictions` parameter is a np.ndarray that contains the predicted class labels for each
    data point in the `features` array. Each element in the `predictions` array corresponds to the
    predicted class label of the corresponding data point in the `features` array.
</code></pre>

  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="classification.naive_bayes.bernoulli" class="doc doc-heading">
            <code>classification.naive_bayes.bernoulli</code>


</h2>

  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h3 id="classification.naive_bayes.bernoulli.BernoulliNaiveBayes" class="doc doc-heading">
          <code>BernoulliNaiveBayes</code>


</h3>


  <div class="doc doc-contents ">

  
      <p>Defines a class for a probabilistic classifier that can be
trained on features and labels, and used to make predictions and evaluate
the accuracy of the predictions.</p>
<p>Bernoulli Naive Bayes is a probabilistic classifier that assumes that the features are binary (0 or 1).
It is based on Bayes' theorem, which states that the probability of a hypothesis (class) given the data
(features) is equal to the probability of the data given the hypothesis multiplied by the probability of
the hypothesis divided by the probability of the data. In other words, it is the posterior probability of
a hypothesis given the data is equal to the likelihood of the data given the hypothesis multiplied by the
prior probability of the hypothesis divided by the marginal likelihood of the data.</p>


  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h4 id="classification.naive_bayes.bernoulli.BernoulliNaiveBayes.evaluate" class="doc doc-heading">
<code class="highlight language-python"><span class="n">evaluate</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The evaluate function calculates the accuracy of the predictions made by the model.</p>
<h6 id="classification.naive_bayes.bernoulli.BernoulliNaiveBayes.evaluate--parameters">Parameters</h6>
<pre><code>features : np.ndarray
    The `features` parameter is a np.ndarray that represents the input features for training the
    model. It has a shape of `(num_samples, num_features)`, where `num_samples` is the number of
    training samples and `num_features` is the number of features for each sample

labels : np.ndarray
    The "labels" parameter is a np.ndarray that contains the class labels for each data point in the
    "features" array. Each element in the "labels" array corresponds to the class label of the
    corresponding data point in the "features" array
</code></pre>
<h6 id="classification.naive_bayes.bernoulli.BernoulliNaiveBayes.evaluate--returns">Returns</h6>
<pre><code>accuracy : float
    The `accuracy` parameter is a float that represents the accuracy of the model on the given
    features and labels.
</code></pre>

  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="classification.naive_bayes.bernoulli.BernoulliNaiveBayes.fit" class="doc doc-heading">
<code class="highlight language-python"><span class="n">fit</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">smoothing_factor</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The <code>fit</code> function trains a probabilistic classifier using the given features and labels, optimizing
the feature probabilities using gradient descent with momentum-like update.</p>
<h6 id="classification.naive_bayes.bernoulli.BernoulliNaiveBayes.fit--parameters">Parameters</h6>
<pre><code>features : np.ndarray
    The `features` parameter is a np.ndarray that represents the input features for training the
    model. It has a shape of `(num_samples, num_features)`, where `num_samples` is the number of
    training samples and `num_features` is the number of features for each sample

labels : np.ndarray
    The "labels" parameter is a np.ndarray that contains the class labels for each data point in the
    "features" array. Each element in the "labels" array corresponds to the class label of the
    corresponding data point in the "features" array

epochs : int
    The `epochs` parameter is an integer that represents the number of epochs to train the model for.
    An epoch is one iteration over the entire training dataset.

learning_rate : float
    The `learning_rate` parameter is a float that controls the size of the gradient descent step.

verbose : bool
    The `verbose` parameter is a boolean that controls whether or not to print the training accuracy
    for each epoch.

smoothing_factor : float
    The `smoothing_factor` parameter is a float that controls the amount of smoothing to apply to the
    feature probabilities. It is used to prevent the probabilities from becoming too extreme.
</code></pre>

  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="classification.naive_bayes.bernoulli.BernoulliNaiveBayes.predict" class="doc doc-heading">
<code class="highlight language-python"><span class="n">predict</span><span class="p">(</span><span class="n">features</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The <code>predict</code> function takes in a set of features, converts them to binary values, calculates the
log probabilities for each class, and returns the predicted class for each sample.</p>
<h6 id="classification.naive_bayes.bernoulli.BernoulliNaiveBayes.predict--parameters">Parameters</h6>
<pre><code>features : np.ndarray
    The `features` parameter is a np.ndarray that represents the input features for training the
    model. It has a shape of `(num_samples, num_features)`, where `num_samples` is the number of
</code></pre>

  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="classification.logistic_regression" class="doc doc-heading">
            <code>classification.logistic_regression</code>


</h2>

  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h3 id="classification.logistic_regression.LogisticRegression" class="doc doc-heading">
          <code>LogisticRegression</code>


</h3>


  <div class="doc doc-contents ">

  
      <p>Defines a class that implements a logistic regression model with various parameters
and methods for training, testing, and evaluating the model.</p>
<p>Logistic regression is a classification algorithm used to predict the probability of a categorical
dependent variable. In logistic regression, the dependent variable is a binary variable that contains data
coded as 1 (yes, success, etc.) or 0 (no, failure, etc.). In other words, the logistic regression model
predicts P(Y=1) as a function of X.</p>


  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h4 id="classification.logistic_regression.LogisticRegression.evaluate" class="doc doc-heading">
<code class="highlight language-python"><span class="n">evaluate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The evaluate function returns the score of a model on a given dataset.</p>
<h6 id="classification.logistic_regression.LogisticRegression.evaluate--parameters">Parameters</h6>
<pre><code>X : np.ndarray
    The parameter X represents the input data or features that will be used to make predictions or
    classifications. It could be a matrix or an array-like object

y : np.ndarray
    The parameter `y` represents the target variable or the dependent variable. It is the variable
    that we are trying to predict or model. In the context of machine learning, `y` typically
    represents the labels or classes of the data
</code></pre>
<h6 id="classification.logistic_regression.LogisticRegression.evaluate--returns">Returns</h6>
<pre><code>tuple(float, float)
    The function returns a tuple containing the accuracy and loss of the model on the given dataset.
</code></pre>

  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="classification.logistic_regression.LogisticRegression.fit" class="doc doc-heading">
<code class="highlight language-python"><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">X_val</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y_val</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The <code>fit</code> function trains a linear regression model using Mini-batch Gradient Descent with early
stopping and learning rate scheduling.</p>
<h6 id="classification.logistic_regression.LogisticRegression.fit--parameters">Parameters</h6>
<pre><code>X : np.ndarray
    The parameter X represents the input features or data that you want to use to train the model

y : np.ndarray
    The parameter `y` represents the target variable or the dependent variable in the supervised
    learning problem. It is a np.ndarray containing the true values of the target variable for the
    corresponding samples in the input data `X`

X_val : np.ndarray, optional
    The parameter `X_val` represents the input features or data that you want to use to validate the
    model. It is a np.ndarray containing the features of the validation set

y_val : np.ndarray, optional
    The parameter `y_val` represents the target variable or the dependent variable in the supervised
    learning problem. It is a np.ndarray containing the true values of the target variable for the
    corresponding samples in the input data `X_val`

random_seed : int, optional
    The parameter `random_seed` is used to set the random seed for reproducibility. By setting a
    specific value for `random_seed`, you can ensure that the random initialization of the model's
    weights and any other random operations are consistent across different runs of the code.
</code></pre>

  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="classification.logistic_regression.LogisticRegression.get_params" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_params</span><span class="p">()</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The function <code>get_params</code> returns a dictionary containing the values of various parameters.</p>
<h6 id="classification.logistic_regression.LogisticRegression.get_params--returns">Returns</h6>
<pre><code>dict
    A dictionary containing the values of the learning_rate, num_epochs, reg_strength, batch_size,
</code></pre>

  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="classification.logistic_regression.LogisticRegression.predict" class="doc doc-heading">
<code class="highlight language-python"><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The <code>predict</code> function takes in a set of input data <code>X</code> and returns the predicted class labels based
on the highest probability from the <code>predict_proba</code> function.</p>
<h6 id="classification.logistic_regression.LogisticRegression.predict--parameters">Parameters</h6>
<pre><code>X : np.ndarray
    The parameter X represents the input data for which you want to make predictions. It could be a
    single data point or a collection of data points. The shape of X should match the shape of the
    training data used to train the model
</code></pre>
<h6 id="classification.logistic_regression.LogisticRegression.predict--returns">Returns</h6>
<pre><code>np.ndarray
    The `predict` function returns a np.ndarray containing the predicted class labels for each data
    point in `X`.
</code></pre>

  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="classification.logistic_regression.LogisticRegression.predict_proba" class="doc doc-heading">
<code class="highlight language-python"><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The <code>predict_proba</code> function takes in a set of features <code>X</code>, scales the features, adds a column of
ones to the scaled features, performs matrix multiplication with the coefficients, applies the
sigmoid function to the logits, and returns the probabilities.</p>
<h6 id="classification.logistic_regression.LogisticRegression.predict_proba--parameters">Parameters</h6>
<pre><code>X : np.ndarray
    The parameter X represents the input data for which you want to make predictions. It could be a
    single data point or a collection of data points. The shape of X should match the shape of the
    training data used to train the model
</code></pre>
<h6 id="classification.logistic_regression.LogisticRegression.predict_proba--returns">Returns</h6>
<pre><code>np.ndarray
    The `predict_proba` function returns a np.ndarray containing the predicted probabilities for
    each class.
</code></pre>

  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="classification.logistic_regression.LogisticRegression.score" class="doc doc-heading">
<code class="highlight language-python"><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The function calculates the accuracy and loss of a binary classification model using TensorFlow's
binary cross-entropy loss function.</p>
<h6 id="classification.logistic_regression.LogisticRegression.score--parameters">Parameters</h6>
<pre><code>X : np.ndarray
    The parameter X represents the input data or features that will be used to make predictions or
    classifications. It could be a matrix or an array-like object

y : np.ndarray
    The parameter `y` represents the target variable or the dependent variable. It is the variable
    that we are trying to predict or model. In the context of machine learning, `y` typically
    represents the labels or classes of the data
</code></pre>
<h6 id="classification.logistic_regression.LogisticRegression.score--returns">Returns</h6>
<pre><code>tuple(float, float)
    The function returns a tuple containing the accuracy and loss of the model on the given dataset.
</code></pre>

  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="classification.logistic_regression.LogisticRegression.set_params" class="doc doc-heading">
<code class="highlight language-python"><span class="n">set_params</span><span class="p">(</span><span class="n">params</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The function sets the parameters for a machine learning model, including learning rate, number of
epochs, regularization strength, batch size, early stopping patience, regularization method, and
tolerance.</p>
<h6 id="classification.logistic_regression.LogisticRegression.set_params--parameters">Parameters</h6>
<pre><code>params : dict
    A dictionary containing the values of the learning_rate, num_epochs, reg_strength, batch_size,
    early_stopping_patience, regularization, and tolerance attributes.
</code></pre>

  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="classification.logistic_regression.LogisticRegression.sigmoid" class="doc doc-heading">
<code class="highlight language-python"><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The sigmoid function returns the value of 1 divided by 1 plus the exponential of the negative input
value.</p>
<p>Sigmoid function is a mathematical function that takes any real value and maps it to a value between
0 and 1. It is a non-linear function used for binary classification tasks.</p>
<h6 id="classification.logistic_regression.LogisticRegression.sigmoid--parameters">Parameters</h6>
<pre><code>z : tf.Tensor
    The parameter "z" is a tensor representing the input to the sigmoid function. It can be a 1D or
    2D tensor
</code></pre>
<h6 id="classification.logistic_regression.LogisticRegression.sigmoid--returns">Returns</h6>
<pre><code>tf.Tensor
    The sigmoid function is being returned.
</code></pre>

  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="classification.logistic_regression.LogisticRegression.softmax" class="doc doc-heading">
<code class="highlight language-python"><span class="n">softmax</span><span class="p">(</span><span class="n">z</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The softmax function takes in a vector of values and returns a vector of probabilities that sum up
to 1.</p>
<p>Softmax function is a mathematical function that takes a vector of real numbers and normalizes it into
a probability distribution consisting of probabilities proportional to the exponentials of the input
numbers. In other words, the softmax function converts a vector of numbers into a vector of
probabilities that sum up to 1.</p>
<h6 id="classification.logistic_regression.LogisticRegression.softmax--parameters">Parameters</h6>
<pre><code>z : tf.Tensor
    The parameter "z" is a tensor representing the input to the softmax function. It can be a 1D or
    2D tensor
</code></pre>
<h6 id="classification.logistic_regression.LogisticRegression.softmax--returns">Returns</h6>
<pre><code>tf.Tensor
    The softmax function is being returned.
</code></pre>

  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="classification.logistic_regression.LogisticRegression.train_test_split" class="doc doc-heading">
<code class="highlight language-python"><span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The function <code>train_test_split</code> splits the input data <code>X</code> and target variable <code>y</code> into training and
testing sets based on the specified test size and random state.</p>
<h6 id="classification.logistic_regression.LogisticRegression.train_test_split--parameters">Parameters</h6>
<pre><code>X : np.ndarray
    The parameter X represents the input features or data that you want to split into training and
    testing sets

y : np.ndarray
    The parameter `y` represents the target variable or the dependent variable in the supervised
    learning problem. It is a np.ndarray containing the true values of the target variable for the
    corresponding samples in the input data `X`

test_size : float, optional
    The parameter `test_size` represents the proportion of the dataset that should be allocated to
    the test set. The default value is 0.2, which means that 20% of the data will be used for testing

random_state : int, optional
    The parameter `random_state` is used to set the random seed for reproducibility. By setting a
    specific value for `random_state`, you can ensure that the random initialization of the model's
    weights and any other random operations are consistent across different runs of the code.
</code></pre>
<h6 id="classification.logistic_regression.LogisticRegression.train_test_split--returns">Returns</h6>
<pre><code>np.ndarray
    The function returns four np.ndarrays: X_train, X_test, y_train, and y_test. X_train and y_train
</code></pre>

  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="classification.decision_tree" class="doc doc-heading">
            <code>classification.decision_tree</code>


</h2>

  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h3 id="classification.decision_tree.DecisionTree" class="doc doc-heading">
          <code>DecisionTree</code>


</h3>


  <div class="doc doc-contents ">

  
      <p>Defines a class that implements a machine learning model using
TensorFlow Decision Forests (TF-DF) for classification or regression tasks,
including methods for loading datasets, training the model, making predictions,
and evaluating the model's performance.</p>
<p>TensorFlow Decision Forests (TF-DF) is a library for training and serving
TensorFlow models for decision tasks. It is an open-source library that
provides a collection of state-of-the-art algorithms for decision tasks,
including classification, regression, ranking, and clustering.</p>
<p>Decision trees (DT) are a type of supervised learning algorithm that can be used
for both classification and regression tasks. They are a popular choice for
many machine learning problems because they are easy to understand and
interpret, and they can be used to solve a wide variety of problems.</p>
<p>CART (Classification and Regression Trees) is a decision tree learning
algorithm that uses the Gini impurity measure to determine the best split at
each node. It is a popular choice for many machine learning problems because
it is easy to understand and interpret, and it can be used to solve a wide
variety of problems.</p>
<p>Random forests (RFs) are an ensemble learning method that combines multiple
decision trees to create a more powerful model. They are a popular choice
for many machine learning problems because they are easy to understand and
interpret, and they can be used to solve a wide variety of problems.</p>
<p>Gradient Boosted Trees (GBTs) are a type of supervised learning algorithm that
can be used for both classification and regression tasks. They are a popular
choice for many machine learning problems because they are easy to understand
and interpret, and they can be used to solve a wide variety of problems.</p>


  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">



<h4 id="classification.decision_tree.DecisionTree.evaluate" class="doc doc-heading">
<code class="highlight language-python"><span class="n">evaluate</span><span class="p">()</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The <code>evaluate</code> function evaluates a machine learning model on a test dataset and returns the
evaluation metrics.</p>
<h6 id="classification.decision_tree.DecisionTree.evaluate--returns">Returns</h6>
<pre><code>The evaluation results of the model on the test dataset. It returns a dictionary with the evaluation
metrics as keys and their corresponding values.
</code></pre>

  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="classification.decision_tree.DecisionTree.fit" class="doc doc-heading">
<code class="highlight language-python"><span class="n">fit</span><span class="p">(</span><span class="n">early_stopping_patience</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">_metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The <code>fit</code> function trains a model using stochastic gradient descent optimizer with early stopping
and specified hyperparameters.</p>
<h6 id="classification.decision_tree.DecisionTree.fit--parameters">Parameters</h6>
<pre><code>early_stopping_patience : int, optional
    The early_stopping_patience parameter determines the number of epochs to wait before stopping
    the training process if the validation loss does not improve. If the validation loss does not
    improve for the specified number of epochs, training will be stopped early, defaults to 5
    (optional)

learning_rate : float, optional
    The learning rate determines the step size at each iteration while training the model. It
    controls how much the model's weights are updated based on the calculated gradients. A higher
    learning rate can result in faster convergence but may also cause the model to overshoot the
    optimal solution. On the other hand, a lower learning rate can result in slower convergence but
    may also result in a more stable model, defaults to 0.001 (optional)

momentum : float, optional
    Momentum is a hyperparameter used in optimization algorithms, such as Stochastic Gradient
    Descent (SGD), to accelerate convergence and escape local minima. It determines the contribution
    of the previous update to the current update of the model's weights, defaults to 0.9 (optional)

_metrics : list, optional
    _metrics is a list of metrics that will be used to evaluate the model's performance during
    training and validation. These metrics can include accuracy, precision, recall, F1 score, etc,
    defaults to ["accuracy"] (optional)
</code></pre>

  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="classification.decision_tree.DecisionTree.get_params" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_params</span><span class="p">()</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The function <code>get_params</code> returns the configuration of the model.
Returns</p>
<hr />
<pre><code>The configuration of the model.
</code></pre>

  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="classification.decision_tree.DecisionTree.info" class="doc doc-heading">
<code class="highlight language-python"><span class="n">info</span><span class="p">()</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The <code>info</code> function returns a summary of the model.
Returns</p>
<hr />
<pre><code>A summary of the model.
</code></pre>

  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="classification.decision_tree.DecisionTree.load_dataset" class="doc doc-heading">
<code class="highlight language-python"><span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_df</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">test_ratio</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The function <code>load_dataset</code> takes a dataset dataframe, splits it into train, validation, and test
sets, converts them into TensorFlow datasets, and calculates class weights.</p>
<h6 id="classification.decision_tree.DecisionTree.load_dataset--parameters">Parameters</h6>
<pre><code>dataset_df : pandas.DataFrame
    The dataset_df parameter is a pandas DataFrame that contains the dataset you want to load. It
    should have the features as columns and the corresponding labels as a separate column

label : str
    The "label" parameter is the column name of the target variable in the dataset. It is the
    variable that you want to predict or classify

test_ratio : float, optional
    The `test_ratio` parameter is the ratio of the dataset that should be used for testing. It
    determines the proportion of the dataset that will be split into the test set. The remaining
    portion of the dataset will be used for training and validation, by default 0.2
</code></pre>

  </div>

</div>


<div class="doc doc-object doc-function">



<h4 id="classification.decision_tree.DecisionTree.predict" class="doc doc-heading">
<code class="highlight language-python"><span class="n">predict</span><span class="p">(</span><span class="n">length</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">)</span></code>

</h4>


  <div class="doc doc-contents ">
  
      <p>The <code>predict</code> function takes in a length and split parameter, and returns the predictions made by
the model on the specified dataset split.</p>
<h6 id="classification.decision_tree.DecisionTree.predict--parameters">Parameters</h6>
<pre><code>length : int, optional
    The `length` parameter specifies the number of samples to be taken from the dataset. It
    determines how many samples will be used for prediction, defaults to 3 (optional)

split : str, optional
    The "split" parameter determines whether to use the test or train dataset for prediction. If
    "split" is set to "test", the function will use the test dataset and if it is set to "train",
    the function will use the train dataset, defaults to test (optional)
</code></pre>
<h6 id="classification.decision_tree.DecisionTree.predict--returns">Returns</h6>
<pre><code>The predictions made by the model on the specified dataset (either the test dataset or the train
dataset).
</code></pre>

  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../reg/" class="btn btn-neutral float-left" title="Regression"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../tutorials/" class="btn btn-neutral float-right" title="Tutorials">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/siddhantpathakk/tensorflow-ml" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../reg/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../tutorials/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
