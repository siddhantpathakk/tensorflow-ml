{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes classifier example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_ml.classification.naive_bayes.bernoulli import BernoulliNaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the artificial dataset\n",
    "num_samples = 200\n",
    "num_features = 4\n",
    "num_classes = 2\n",
    "\n",
    "# Generate random binary features\n",
    "features = np.random.randint(0, 2, size=(num_samples, num_features))\n",
    "\n",
    "# Generate random class labels (0 or 1)\n",
    "labels = np.random.randint(0, num_classes, size=num_samples)\n",
    "\n",
    "# Convert the dataset into a pandas DataFrame for convenience\n",
    "df = pd.DataFrame(features, columns=[f'Feature_{i+1}' for i in range(num_features)])\n",
    "df['Label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_1  Feature_2  Feature_3  Feature_4  Label\n",
       "0          0          1          0          0      0\n",
       "1          0          1          0          0      1\n",
       "2          0          1          0          0      0\n",
       "3          0          0          1          0      0\n",
       "4          1          1          1          0      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already defined and trained the BernoulliNaiveBayes class\n",
    "# Split the dataset into training and testing sets\n",
    "train_size = int(0.8 * num_samples)\n",
    "training_data = df[:train_size]\n",
    "testing_data = df[train_size:]\n",
    "\n",
    "# Extract features and labels both as float32\n",
    "training_features = training_data.drop('Label', axis=1)\n",
    "training_labels = training_data['Label']\n",
    "testing_features = testing_data.drop('Label', axis=1)\n",
    "testing_labels = testing_data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/siddhantpathak/Desktop/Projects/tensorflow-ml/tensorflow_ml/classification/naive_bayes/bernoulli.py\", line 101, in train_step  *\n        log_likelihoods += class_priors_broadcasted\n\n    ValueError: Dimensions must be equal, but are 32 and 160 for '{{node add}} = AddV2[T=DT_DOUBLE](Cast, Tile_1)' with input shapes: [32,2], [160,2].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m bnb \u001b[39m=\u001b[39m BernoulliNaiveBayes(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, smoothing\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m bnb\u001b[39m.\u001b[39mfit(training_features, training_labels, validation_data\u001b[39m=\u001b[39m(testing_features, testing_labels))\n",
      "File \u001b[0;32m~/Desktop/Projects/tensorflow-ml/tensorflow_ml/classification/naive_bayes/bernoulli.py:128\u001b[0m, in \u001b[0;36mBernoulliNaiveBayes.fit\u001b[0;34m(self, features, labels, epochs, patience, validation_data)\u001b[0m\n\u001b[1;32m    125\u001b[0m num_batches \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[39mfor\u001b[39;00m batch_features, batch_labels \u001b[39min\u001b[39;00m dataset:\n\u001b[0;32m--> 128\u001b[0m     batch_loss \u001b[39m=\u001b[39m train_step(batch_features, batch_labels)\n\u001b[1;32m    129\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_loss\n\u001b[1;32m    130\u001b[0m     num_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyalgo/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/ll/h2ldzwfj6kl5qkxyrsrp33p80000gn/T/__autograph_generated_fileptu0g0ma.py:23\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(batch_features, batch_labels)\u001b[0m\n\u001b[1;32m     21\u001b[0m     log_likelihoods \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mcast, (ag__\u001b[39m.\u001b[39mld(log_likelihoods), ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mfloat64), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     22\u001b[0m     log_likelihoods \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(log_likelihoods)\n\u001b[0;32m---> 23\u001b[0m     log_likelihoods \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m class_priors_broadcasted\n\u001b[1;32m     24\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mreduce_mean, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mreduce_sum, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39msparse_softmax_cross_entropy_with_logits, (), \u001b[39mdict\u001b[39m(labels\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(batch_labels), logits\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(log_likelihoods)), fscope),), \u001b[39mdict\u001b[39m(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), fscope),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     25\u001b[0m grads \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tape)\u001b[39m.\u001b[39mgradient, (ag__\u001b[39m.\u001b[39mld(loss), [ag__\u001b[39m.\u001b[39mld(class_priors_tf), ag__\u001b[39m.\u001b[39mld(feature_probabilities_tf)]), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/siddhantpathak/Desktop/Projects/tensorflow-ml/tensorflow_ml/classification/naive_bayes/bernoulli.py\", line 101, in train_step  *\n        log_likelihoods += class_priors_broadcasted\n\n    ValueError: Dimensions must be equal, but are 32 and 160 for '{{node add}} = AddV2[T=DT_DOUBLE](Cast, Tile_1)' with input shapes: [32,2], [160,2].\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNaiveBayes(learning_rate=0.01, momentum=0.9, batch_size=32, smoothing=1.0)\n",
    "bnb.fit(training_features, training_labels, validation_data=(testing_features, testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "accuracy = bnb.evaluate(testing_features, testing_labels)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# create artificial classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=2, random_state=1) \n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "# split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.569995</td>\n",
       "      <td>-0.130200</td>\n",
       "      <td>3.160751</td>\n",
       "      <td>-4.359364</td>\n",
       "      <td>-1.612720</td>\n",
       "      <td>-1.393521</td>\n",
       "      <td>-2.489249</td>\n",
       "      <td>-1.930941</td>\n",
       "      <td>3.261304</td>\n",
       "      <td>2.056921</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.341293</td>\n",
       "      <td>2.513214</td>\n",
       "      <td>-0.804166</td>\n",
       "      <td>1.291966</td>\n",
       "      <td>2.057731</td>\n",
       "      <td>-3.110983</td>\n",
       "      <td>1.465830</td>\n",
       "      <td>6.247344</td>\n",
       "      <td>-1.927694</td>\n",
       "      <td>2.950315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.275400</td>\n",
       "      <td>3.365615</td>\n",
       "      <td>0.171644</td>\n",
       "      <td>1.248620</td>\n",
       "      <td>0.302498</td>\n",
       "      <td>-1.137814</td>\n",
       "      <td>-1.608199</td>\n",
       "      <td>2.746938</td>\n",
       "      <td>0.134924</td>\n",
       "      <td>2.003395</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.357846</td>\n",
       "      <td>0.905176</td>\n",
       "      <td>-0.259241</td>\n",
       "      <td>0.930414</td>\n",
       "      <td>0.112336</td>\n",
       "      <td>0.143484</td>\n",
       "      <td>-0.367149</td>\n",
       "      <td>0.658955</td>\n",
       "      <td>-0.269128</td>\n",
       "      <td>0.155807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.722477</td>\n",
       "      <td>0.324236</td>\n",
       "      <td>2.906472</td>\n",
       "      <td>-0.021218</td>\n",
       "      <td>-2.867399</td>\n",
       "      <td>1.591744</td>\n",
       "      <td>0.620849</td>\n",
       "      <td>3.383528</td>\n",
       "      <td>0.945621</td>\n",
       "      <td>3.498071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  2.569995 -0.130200  3.160751 -4.359364 -1.612720 -1.393521 -2.489249   \n",
       "1  0.341293  2.513214 -0.804166  1.291966  2.057731 -3.110983  1.465830   \n",
       "2  2.275400  3.365615  0.171644  1.248620  0.302498 -1.137814 -1.608199   \n",
       "3  0.357846  0.905176 -0.259241  0.930414  0.112336  0.143484 -0.367149   \n",
       "4 -2.722477  0.324236  2.906472 -0.021218 -2.867399  1.591744  0.620849   \n",
       "\n",
       "          7         8         9  0  \n",
       "0 -1.930941  3.261304  2.056921  1  \n",
       "1  6.247344 -1.927694  2.950315  0  \n",
       "2  2.746938  0.134924  2.003395  0  \n",
       "3  0.658955 -0.269128  0.155807  1  \n",
       "4  3.383528  0.945621  3.498071  0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_ml.classification.naive_bayes.gaussian import GaussianNaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0, None)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/pyalgo/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/pyalgo/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyalgo/lib/python3.11/site-packages/pandas/_libs/index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), 0, None)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m gnb \u001b[39m=\u001b[39m GaussianNaiveBayes()\n\u001b[0;32m----> 2\u001b[0m gnb\u001b[39m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/Desktop/Projects/tensorflow-ml/tensorflow_ml/classification/naive_bayes/gaussian.py:46\u001b[0m, in \u001b[0;36mGaussianNaiveBayes.fit\u001b[0;34m(self, features, labels, epochs)\u001b[0m\n\u001b[1;32m     44\u001b[0m log_likelihoods \u001b[39m=\u001b[39m []\n\u001b[1;32m     45\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features):\n\u001b[0;32m---> 46\u001b[0m     log_likelihoods\u001b[39m.\u001b[39mappend(tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mlog(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gaussian_likelihood(features[:, i, \u001b[39mNone\u001b[39;00m], feature_params_tf[:, i, \u001b[39m0\u001b[39m], feature_params_tf[:, i, \u001b[39m1\u001b[39m])))\n\u001b[1;32m     48\u001b[0m log_likelihoods \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_sum(log_likelihoods, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mlog(class_priors_tf)\n\u001b[1;32m     49\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mtf\u001b[39m.\u001b[39mreduce_mean(tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39msparse_softmax_cross_entropy_with_logits(labels\u001b[39m=\u001b[39mlabels, logits\u001b[39m=\u001b[39mlog_likelihoods))\n",
      "File \u001b[0;32m~/miniconda3/envs/pyalgo/lib/python3.11/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/pyalgo/lib/python3.11/site-packages/pandas/core/indexes/base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m         \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m         \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m         \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m-> 3809\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m   3810\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m \u001b[39m# GH#42269\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyalgo/lib/python3.11/site-packages/pandas/core/indexes/base.py:5925\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5921\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m   5922\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   5923\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   5924\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 5925\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 0, None)"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNaiveBayes()\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
