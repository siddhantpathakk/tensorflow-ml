{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the artificial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create synthetic data\n",
    "np.random.seed(123)\n",
    "num_samples = 200000\n",
    "X1_class0 = np.random.normal(loc=5, scale=1, size=num_samples // 2)\n",
    "X2_class0 = np.random.normal(loc=3, scale=1, size=num_samples // 2)\n",
    "X3_class0 = np.random.normal(loc=8, scale=2, size=num_samples // 2)\n",
    "X4_class0 = np.random.normal(loc=4, scale=2, size=num_samples // 2)\n",
    "X5_class0 = np.random.normal(loc=6, scale=1, size=num_samples // 2)\n",
    "\n",
    "X1_class1 = np.random.normal(loc=10, scale=1, size=num_samples // 2)\n",
    "X2_class1 = np.random.normal(loc=8, scale=1, size=num_samples // 2)\n",
    "X3_class1 = np.random.normal(loc=15, scale=2, size=num_samples // 2)\n",
    "X4_class1 = np.random.normal(loc=12, scale=2, size=num_samples // 2)\n",
    "X5_class1 = np.random.normal(loc=18, scale=1, size=num_samples // 2)\n",
    "\n",
    "# Create feature matrix X and target vector y\n",
    "X_class0 = np.column_stack((X1_class0, X2_class0, X3_class0, X4_class0, X5_class0))\n",
    "X_class1 = np.column_stack((X1_class1, X2_class1, X3_class1, X4_class1, X5_class1))\n",
    "X = np.vstack((X_class0, X_class1))\n",
    "\n",
    "y_class0 = np.zeros(num_samples // 2)\n",
    "y_class1 = np.ones(num_samples // 2)\n",
    "y = np.concatenate((y_class0, y_class1))\n",
    "\n",
    "# Shuffle the data\n",
    "indices = np.arange(num_samples)\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Convert data to a Pandas DataFrame\n",
    "data = pd.DataFrame({'X1': X[:, 0], 'X2': X[:, 1], 'X3': X[:, 2], 'X4': X[:, 3], 'X5': X[:, 4], 'y': y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = data[['X1', 'X2', 'X3', 'X4', 'X5']].values\n",
    "y = data['y'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution of the training set:  (array([0., 1.]), array([80031, 79969]))\n",
      "Class distribution of the test set:  (array([0., 1.]), array([19969, 20031]))\n"
     ]
    }
   ],
   "source": [
    "# get the class distribution of the training set\n",
    "print(\"Class distribution of the training set: \", np.unique(y_train, return_counts=True))\n",
    "print(\"Class distribution of the test set: \", np.unique(y_test, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_ml.classification.logistic_regression import LogisticRegression\n",
    "\n",
    "# Initialize and set hyperparameters for the LogisticRegression class\n",
    "logistic_regression = LogisticRegression()\n",
    "params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'num_epochs': 100,\n",
    "    'batch_size': 32,\n",
    "    'reg_strength': 0.1,\n",
    "    'early_stopping_patience': 5,\n",
    "    'regularization': 'l2'\n",
    "}\n",
    "logistic_regression.set_params(params)\n",
    "\n",
    "# Train the model\n",
    "logistic_regression.fit(X_train, y_train, random_seed=42, X_val=X_test[:100], y_val=y_test[:100])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy, cross_entropy_loss = logistic_regression.score(X_test, y_test)\n",
    "accuracy2, cross_entropy_loss2 = logistic_regression.score(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy on test set :\\t{accuracy*100:.4f} %\")\n",
    "print(f\"Accuracy on train set :\\t{accuracy2*100:.4f} %\")\n",
    "\n",
    "print(f\"\\nCross-entropy loss on test set :\\t{cross_entropy_loss:.4f}\")\n",
    "print(f\"Cross-entropy loss on train set :\\t{cross_entropy_loss2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare against the sklearn implementation of logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr = LR()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
